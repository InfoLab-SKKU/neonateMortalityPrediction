{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> <font color='purple'> Dynamic Ensemble Machine Learning Models (Mix Pool)</font></center> \n",
    "#### <center>Firuz Juraev (Sungkyunkwan Unniversity)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Basic Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Single ML Models Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Static ML Models Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> DES Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deslib.des import DESP\n",
    "from deslib.des import KNORAE\n",
    "from deslib.des import KNORAU\n",
    "from deslib.des import METADES\n",
    "from deslib.des import DESKNN # new \n",
    "from deslib.des import KNOP # new "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> DCS Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deslib.dcs import MCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Processing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score, \n",
    "                             f1_score,\n",
    "                             roc_auc_score, \n",
    "                             auc)\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_upsampled = pd.read_csv(\"Data/Resampled_neonates_train_data_4.csv\")\n",
    "test_dataset_upsampled = pd.read_csv(\"Data/Resampled_neonates_test_data_4.csv\")\n",
    "\n",
    "X_train = train_dataset_upsampled.drop([\"DEAD\"], axis=1) \n",
    "y_train = train_dataset_upsampled[\"DEAD\"]\n",
    "\n",
    "X_test = test_dataset_upsampled.drop([\"DEAD\"], axis=1) \n",
    "y_test = test_dataset_upsampled[\"DEAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "## Scaling \n",
    "X_train_mm_scaled = Min_max_scaler.transform(X_train)\n",
    "X_test_mm_scaled = Min_max_scaler.transform(X_test)\n",
    "\n",
    "## Numpy Array to DataFrame \n",
    "df_train_mm_scaled = pd.DataFrame(X_train_mm_scaled, columns = columns)\n",
    "df_test_mm_scaled = pd.DataFrame(X_test_mm_scaled, columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>respRate_std</th>\n",
       "      <th>respRate_var</th>\n",
       "      <th>skinTemperature_var</th>\n",
       "      <th>skinTemperature_std</th>\n",
       "      <th>heartRate_std</th>\n",
       "      <th>heartRate_var</th>\n",
       "      <th>bpCuffMean_var</th>\n",
       "      <th>sao2_std</th>\n",
       "      <th>sao2_var</th>\n",
       "      <th>...</th>\n",
       "      <th>BIRTH_WEIGHT</th>\n",
       "      <th>bpCuffSystolic_mean</th>\n",
       "      <th>bpCuffDiastolic_mean</th>\n",
       "      <th>temperature_var</th>\n",
       "      <th>sao2_mean</th>\n",
       "      <th>temperature_std</th>\n",
       "      <th>glucometer_mean</th>\n",
       "      <th>bpCuffMean_mean</th>\n",
       "      <th>PLATELET</th>\n",
       "      <th>D10W_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.775318</td>\n",
       "      <td>0.422245</td>\n",
       "      <td>0.178291</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.134078</td>\n",
       "      <td>0.22911</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.053294</td>\n",
       "      <td>0.097817</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264267</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.881455</td>\n",
       "      <td>0.125281</td>\n",
       "      <td>0.312593</td>\n",
       "      <td>0.310696</td>\n",
       "      <td>0.281330</td>\n",
       "      <td>0.151138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.709668</td>\n",
       "      <td>0.583964</td>\n",
       "      <td>0.341014</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.086672</td>\n",
       "      <td>0.28258</td>\n",
       "      <td>0.086102</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.080938</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437819</td>\n",
       "      <td>0.644907</td>\n",
       "      <td>0.479330</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.926056</td>\n",
       "      <td>0.061399</td>\n",
       "      <td>0.272551</td>\n",
       "      <td>0.351928</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.196784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_mean  respRate_std  respRate_var  skinTemperature_var  \\\n",
       "0          0.775318      0.422245      0.178291             0.017977   \n",
       "1          0.709668      0.583964      0.341014             0.007512   \n",
       "\n",
       "   skinTemperature_std  heartRate_std  heartRate_var  bpCuffMean_var  \\\n",
       "0             0.134078        0.22911       0.057937        0.053294   \n",
       "1             0.086672        0.28258       0.086102        0.020317   \n",
       "\n",
       "   sao2_std  sao2_var  ...  BIRTH_WEIGHT  bpCuffSystolic_mean  \\\n",
       "0  0.097817  0.009568  ...      0.264267             0.602649   \n",
       "1  0.080938  0.006551  ...      0.437819             0.644907   \n",
       "\n",
       "   bpCuffDiastolic_mean  temperature_var  sao2_mean  temperature_std  \\\n",
       "0              0.457143         0.015695   0.881455         0.125281   \n",
       "1              0.479330         0.003770   0.926056         0.061399   \n",
       "\n",
       "   glucometer_mean  bpCuffMean_mean  PLATELET  D10W_MEAN  \n",
       "0         0.312593         0.310696  0.281330   0.151138  \n",
       "1         0.272551         0.351928  0.392157   0.196784  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tain_mm_scaled_df = df_train_mm_scaled[:]\n",
    "tain_mm_scaled_df[\"DEAD\"] = y_train \n",
    "\n",
    "test_mm_scaled_df = df_test_mm_scaled[:] \n",
    "test_mm_scaled_df[\"DEAD\"] = y_test\n",
    "\n",
    "\n",
    "importances = mutual_info_classif(df_train_mm_scaled, y_train)\n",
    "feat_importance = pd.Series(importances, tain_mm_scaled_df.columns[0:len(tain_mm_scaled_df.columns)-1])\n",
    "    \n",
    "feat_importance = feat_importance.sort_values(ascending=False)\n",
    "    \n",
    "selected_features = feat_importance[:30]\n",
    "selected_features_list_mm_scaled = selected_features.index.to_list()\n",
    "\n",
    "\n",
    "tain_mm_scaled_df[selected_features_list_mm_scaled].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mm = df_train_mm_scaled[selected_features_list_mm_scaled][:]\n",
    "X_test_mm = df_test_mm_scaled[selected_features_list_mm_scaled][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'> Hold-out Test (With Mix ML) - (+FS, +HO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_result(model, dsel_x, dsel_y, test_x, test_y): \n",
    "    model.fit(dsel_x, dsel_y)\n",
    "    y_preds = model.predict(test_x) \n",
    "    yproba = model.predict_proba(test_x)[::,1] \n",
    "    \n",
    "    acc = accuracy_score(test_y, y_preds)\n",
    "    prec = precision_score(test_y, y_preds)\n",
    "    rec = recall_score(test_y, y_preds)\n",
    "    f1 = f1_score(test_y, y_preds)\n",
    "    fpr, tpr, _ = roc_curve(test_y,  yproba) \n",
    "    auc = roc_auc_score(test_y, yproba)\n",
    "    \n",
    "    return {\"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\":f1, \"fpr\": fpr, \"tpr\":tpr, \"auc\": auc}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out_mix_ML(): \n",
    "    rng = np.random.RandomState(42) \n",
    "    X_train, X_dsel, y_train_en, y_dsel = train_test_split(X_train_mm, y_train, test_size=0.40, random_state=rng)\n",
    "    model_dt1 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    model_dt2 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    model_dt3 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    model_dt4 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    model_dt5 = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    voting_classifiers = [(\"dt1\", model_dt1),\n",
    "                          (\"dt2\", model_dt2),\n",
    "                          (\"dt3\", model_dt3),\n",
    "                          (\"dt4\", model_dt4), \n",
    "                          (\"dt5\", model_dt5)]\n",
    "    \n",
    "    model_svc = SVC(kernel='linear', C=0.007, gamma=0.2, degree=3, probability=True, class_weight='balanced')\n",
    "    model_dt = DecisionTreeClassifier(criterion='entropy', max_depth=3) # depth was 3  \n",
    "    model_lr = LogisticRegression(penalty='l2', C=0.002)\n",
    "    model_ml_perceptron = MLPClassifier(solver='adam', max_iter=11, verbose=10,learning_rate_init=.003)\n",
    "    model_nb = GaussianNB(var_smoothing=0.1)\n",
    "    \n",
    "    model_rf  = RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=3)\n",
    "    model_cat = MLPClassifier(solver='adam', max_iter=11, verbose=10,learning_rate_init=.003)\n",
    "    model_lgb = LGBMClassifier(max_depth=1, n_estimators=150, objective=\"binary\")\n",
    "    model_voting = VotingClassifier(estimators = voting_classifiers, voting='soft') \n",
    "    \n",
    "    model_svc.fit(X_train, y_train_en)\n",
    "    model_dt.fit(X_train, y_train_en)\n",
    "    model_lr.fit(X_train, y_train_en)\n",
    "    model_ml_perceptron.fit(X_train, y_train_en)\n",
    "    model_nb.fit(X_train, y_train_en)\n",
    "    \n",
    "    model_rf.fit(X_train, y_train_en) \n",
    "    model_cat.fit(X_train, y_train_en) \n",
    "    model_lgb.fit(X_train, y_train_en)\n",
    "    model_voting.fit(X_train, y_train_en)\n",
    "    \n",
    "    classifiers_names = [\"MLP\", \"Decision Tree\", \"Logistic Regression\", \"SVC\", \"NB\", \"Random Forest\", \n",
    "                         \"CatBoost\", \"LGBM\", \"MajorityVoting\"] # \"Decision Tree\",\n",
    "    # \"AdaBoost\" , \"LGBM\"\n",
    "    pool_classifiers = [model_ml_perceptron, \n",
    "                        model_dt,\n",
    "                        model_lr, \n",
    "                        model_svc, \n",
    "                        model_nb, \n",
    "                        model_rf, \n",
    "                        model_cat,\n",
    "                        model_lgb,\n",
    "                        model_voting\n",
    "                        ] \n",
    "    c_acc_list = [] \n",
    "    \n",
    "    for cls in pool_classifiers:\n",
    "        y_preds_c = cls.predict(X_test_mm) \n",
    "        c_acc_list.append(accuracy_score(y_test, y_preds_c))           \n",
    "        \n",
    "        \n",
    "    classifiers_results =  {'name': classifiers_names, \n",
    "                            'accuracy': c_acc_list}\n",
    "    \n",
    "    clsDF = pd.DataFrame.from_dict(classifiers_results)\n",
    "        \n",
    "    # DES STARTS\n",
    "    \n",
    "    knorau = KNORAU(pool_classifiers)\n",
    "    kne = KNORAE(pool_classifiers)  \n",
    "    metades = METADES(pool_classifiers)\n",
    "    desknn = DESKNN(pool_classifiers)\n",
    "    mcb = MCB(pool_classifiers)\n",
    "    desp = DESP(pool_classifiers)\n",
    "    knop = KNOP(pool_classifiers)\n",
    "\n",
    "    fire_knorau = KNORAU(pool_classifiers, DFP=True, k=7) \n",
    "    fire_kne = KNORAE(pool_classifiers, DFP=True, k=9)\n",
    "    fire_metades = METADES(pool_classifiers, DFP=True, k=9) \n",
    "    fire_desknn = DESKNN(pool_classifiers, DFP=True, k=9)\n",
    "    fire_mcb = MCB(pool_classifiers, DFP=True, k=7) # 7 was 96%\n",
    "    fire_desp = DESP(pool_classifiers, DFP=True, k=9)\n",
    "    fire_knop = KNOP(pool_classifiers, DFP=True, k=15)\n",
    "    \n",
    "    ensemble_classifiers = [fire_knorau, knorau, fire_kne, kne, fire_metades, metades, fire_desknn, desknn, \n",
    "                            fire_mcb, mcb, fire_desp, desp, fire_knop, knop]\n",
    "    \n",
    "    ensemble_names = [\"FIRE-KNORA-U\", \"KNORA-U\", \"FIRE-KNORA-E\", \"KNORA-E\", \"FIRE-METADES\", \"METADES\",\n",
    "                      \"FIRE-DESKNN\", \"DESKNN\", \"FIRE-MCB\", \"MCB\", \"FIRE-DESP\", \"DESP\", \"FIRE-KNOP\", \"KNOP\"]\n",
    "    \n",
    "    acc_list = [] \n",
    "    precision_list = [] \n",
    "    recall_list = []\n",
    "    f1_lists = [] \n",
    "    auc_list = [] \n",
    "    fpr_list = [] \n",
    "    tpr_list = []\n",
    "    \n",
    "    for e_cls in ensemble_classifiers:\n",
    "        results_dct = get_individual_result(e_cls, X_dsel, y_dsel, X_test_mm, y_test)\n",
    "        acc_list.append(results_dct[\"acc\"])\n",
    "        precision_list.append(results_dct[\"prec\"])\n",
    "        recall_list.append(results_dct[\"rec\"]) \n",
    "        f1_lists.append(results_dct[\"f1\"]) \n",
    "        auc_list.append(results_dct[\"auc\"])\n",
    "        fpr_list.append(results_dct[\"fpr\"])\n",
    "        tpr_list.append(results_dct[\"tpr\"])\n",
    "        \n",
    "\n",
    "    results =  {'name': ensemble_names, \n",
    "                'accuracy': acc_list, \n",
    "                'precision': precision_list, \n",
    "                'recall': recall_list, 'f1': f1_lists, \n",
    "                'auc': auc_list, \n",
    "                'tpr': tpr_list, 'fpr': fpr_list}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "    \n",
    "    return df, clsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65725992\n",
      "Iteration 2, loss = 0.54290633\n",
      "Iteration 3, loss = 0.45412108\n",
      "Iteration 4, loss = 0.39418061\n",
      "Iteration 5, loss = 0.36012913\n",
      "Iteration 6, loss = 0.33657826\n",
      "Iteration 7, loss = 0.32140213\n",
      "Iteration 8, loss = 0.30845671\n",
      "Iteration 9, loss = 0.29507320\n",
      "Iteration 10, loss = 0.28724066\n",
      "Iteration 11, loss = 0.28159370\n",
      "Iteration 1, loss = 0.64464548\n",
      "Iteration 2, loss = 0.53142127\n",
      "Iteration 3, loss = 0.44548697\n",
      "Iteration 4, loss = 0.39387722\n",
      "Iteration 5, loss = 0.36123517\n",
      "Iteration 6, loss = 0.33939984\n",
      "Iteration 7, loss = 0.32395209\n",
      "Iteration 8, loss = 0.31053943\n",
      "Iteration 9, loss = 0.29903933\n",
      "Iteration 10, loss = 0.29111611\n",
      "Iteration 11, loss = 0.28104000\n",
      "Iteration 1, loss = 0.64651586\n",
      "Iteration 2, loss = 0.54006920\n",
      "Iteration 3, loss = 0.45743181\n",
      "Iteration 4, loss = 0.40262038\n",
      "Iteration 5, loss = 0.36978674\n",
      "Iteration 6, loss = 0.34473797\n",
      "Iteration 7, loss = 0.32793946\n",
      "Iteration 8, loss = 0.31469228\n",
      "Iteration 9, loss = 0.30358861\n",
      "Iteration 10, loss = 0.29213466\n",
      "Iteration 11, loss = 0.28519795\n",
      "Iteration 1, loss = 0.62685879\n",
      "Iteration 2, loss = 0.50338416\n",
      "Iteration 3, loss = 0.42480949\n",
      "Iteration 4, loss = 0.38071294\n",
      "Iteration 5, loss = 0.35212072\n",
      "Iteration 6, loss = 0.33664130\n",
      "Iteration 7, loss = 0.31983342\n",
      "Iteration 8, loss = 0.30624617\n",
      "Iteration 9, loss = 0.29701023\n",
      "Iteration 10, loss = 0.28841028\n",
      "Iteration 11, loss = 0.27933557\n",
      "Iteration 1, loss = 0.64066415\n",
      "Iteration 2, loss = 0.53717655\n",
      "Iteration 3, loss = 0.44918044\n",
      "Iteration 4, loss = 0.39250799\n",
      "Iteration 5, loss = 0.35987494\n",
      "Iteration 6, loss = 0.33964140\n",
      "Iteration 7, loss = 0.32349103\n",
      "Iteration 8, loss = 0.31461297\n",
      "Iteration 9, loss = 0.30224162\n",
      "Iteration 10, loss = 0.29111845\n",
      "Iteration 11, loss = 0.28312118\n",
      "Iteration 1, loss = 0.61322764\n",
      "Iteration 2, loss = 0.49158357\n",
      "Iteration 3, loss = 0.41061955\n",
      "Iteration 4, loss = 0.36631197\n",
      "Iteration 5, loss = 0.34099423\n",
      "Iteration 6, loss = 0.32700194\n",
      "Iteration 7, loss = 0.31524697\n",
      "Iteration 8, loss = 0.29983098\n",
      "Iteration 9, loss = 0.28817133\n",
      "Iteration 10, loss = 0.27970389\n",
      "Iteration 11, loss = 0.27386673\n",
      "Iteration 1, loss = 0.63436308\n",
      "Iteration 2, loss = 0.52191073\n",
      "Iteration 3, loss = 0.43708020\n",
      "Iteration 4, loss = 0.38746454\n",
      "Iteration 5, loss = 0.35752256\n",
      "Iteration 6, loss = 0.33425945\n",
      "Iteration 7, loss = 0.31802861\n",
      "Iteration 8, loss = 0.30437958\n",
      "Iteration 9, loss = 0.29617997\n",
      "Iteration 10, loss = 0.28721335\n",
      "Iteration 11, loss = 0.28350795\n",
      "Iteration 1, loss = 0.63353089\n",
      "Iteration 2, loss = 0.50819480\n",
      "Iteration 3, loss = 0.42067714\n",
      "Iteration 4, loss = 0.37418411\n",
      "Iteration 5, loss = 0.34658637\n",
      "Iteration 6, loss = 0.32763985\n",
      "Iteration 7, loss = 0.31344122\n",
      "Iteration 8, loss = 0.29915635\n",
      "Iteration 9, loss = 0.29256701\n",
      "Iteration 10, loss = 0.28441140\n",
      "Iteration 11, loss = 0.27922995\n",
      "Iteration 1, loss = 0.61296411\n",
      "Iteration 2, loss = 0.50452953\n",
      "Iteration 3, loss = 0.42513818\n",
      "Iteration 4, loss = 0.37865443\n",
      "Iteration 5, loss = 0.35157753\n",
      "Iteration 6, loss = 0.32977784\n",
      "Iteration 7, loss = 0.31554994\n",
      "Iteration 8, loss = 0.30641918\n",
      "Iteration 9, loss = 0.29290629\n",
      "Iteration 10, loss = 0.28564815\n",
      "Iteration 11, loss = 0.28048870\n",
      "Iteration 1, loss = 0.64451694\n",
      "Iteration 2, loss = 0.53469577\n",
      "Iteration 3, loss = 0.44553976\n",
      "Iteration 4, loss = 0.38978297\n",
      "Iteration 5, loss = 0.35805206\n",
      "Iteration 6, loss = 0.33518921\n",
      "Iteration 7, loss = 0.32142406\n",
      "Iteration 8, loss = 0.30549716\n",
      "Iteration 9, loss = 0.29620104\n",
      "Iteration 10, loss = 0.28688937\n",
      "Iteration 11, loss = 0.27937857\n",
      "Iteration 1, loss = 0.62052445\n",
      "Iteration 2, loss = 0.49997664\n",
      "Iteration 3, loss = 0.41952945\n",
      "Iteration 4, loss = 0.37216313\n",
      "Iteration 5, loss = 0.34468687\n",
      "Iteration 6, loss = 0.32310687\n",
      "Iteration 7, loss = 0.30741120\n",
      "Iteration 8, loss = 0.29625276\n",
      "Iteration 9, loss = 0.28617885\n",
      "Iteration 10, loss = 0.27762969\n",
      "Iteration 11, loss = 0.26970215\n",
      "Iteration 1, loss = 0.64013643\n",
      "Iteration 2, loss = 0.52663726\n",
      "Iteration 3, loss = 0.43593316\n",
      "Iteration 4, loss = 0.38101455\n",
      "Iteration 5, loss = 0.35213623\n",
      "Iteration 6, loss = 0.33258920\n",
      "Iteration 7, loss = 0.31795588\n",
      "Iteration 8, loss = 0.30781516\n",
      "Iteration 9, loss = 0.29464197\n",
      "Iteration 10, loss = 0.28672381\n",
      "Iteration 11, loss = 0.27944871\n",
      "Iteration 1, loss = 0.65040746\n",
      "Iteration 2, loss = 0.54192754\n",
      "Iteration 3, loss = 0.45593544\n",
      "Iteration 4, loss = 0.39979730\n",
      "Iteration 5, loss = 0.36510460\n",
      "Iteration 6, loss = 0.34321238\n",
      "Iteration 7, loss = 0.33160720\n",
      "Iteration 8, loss = 0.31457440\n",
      "Iteration 9, loss = 0.30479700\n",
      "Iteration 10, loss = 0.29472962\n",
      "Iteration 11, loss = 0.28605428\n",
      "Iteration 1, loss = 0.65511611\n",
      "Iteration 2, loss = 0.54275350\n",
      "Iteration 3, loss = 0.46047543\n",
      "Iteration 4, loss = 0.40495144\n",
      "Iteration 5, loss = 0.37401864\n",
      "Iteration 6, loss = 0.35109833\n",
      "Iteration 7, loss = 0.33358679\n",
      "Iteration 8, loss = 0.31951519\n",
      "Iteration 9, loss = 0.30733371\n",
      "Iteration 10, loss = 0.29634043\n",
      "Iteration 11, loss = 0.28866681\n",
      "Iteration 1, loss = 0.64208614\n",
      "Iteration 2, loss = 0.52358117\n",
      "Iteration 3, loss = 0.43414237\n",
      "Iteration 4, loss = 0.38141326\n",
      "Iteration 5, loss = 0.34956253\n",
      "Iteration 6, loss = 0.32765238\n",
      "Iteration 7, loss = 0.31166116\n",
      "Iteration 8, loss = 0.29821536\n",
      "Iteration 9, loss = 0.28796179\n",
      "Iteration 10, loss = 0.28120649\n",
      "Iteration 11, loss = 0.26999043\n",
      "Iteration 1, loss = 0.63898635\n",
      "Iteration 2, loss = 0.52320501\n",
      "Iteration 3, loss = 0.43949066\n",
      "Iteration 4, loss = 0.38813352\n",
      "Iteration 5, loss = 0.35813444\n",
      "Iteration 6, loss = 0.33833350\n",
      "Iteration 7, loss = 0.32632786\n",
      "Iteration 8, loss = 0.31645579\n",
      "Iteration 9, loss = 0.30370441\n",
      "Iteration 10, loss = 0.29194775\n",
      "Iteration 11, loss = 0.28643367\n",
      "Iteration 1, loss = 0.61678590\n",
      "Iteration 2, loss = 0.49417009\n",
      "Iteration 3, loss = 0.41599715\n",
      "Iteration 4, loss = 0.37102297\n",
      "Iteration 5, loss = 0.34550870\n",
      "Iteration 6, loss = 0.32648702\n",
      "Iteration 7, loss = 0.31229977\n",
      "Iteration 8, loss = 0.30005049\n",
      "Iteration 9, loss = 0.29422611\n",
      "Iteration 10, loss = 0.28476759\n",
      "Iteration 11, loss = 0.27976484\n",
      "Iteration 1, loss = 0.62183462\n",
      "Iteration 2, loss = 0.51188865\n",
      "Iteration 3, loss = 0.43184269\n",
      "Iteration 4, loss = 0.38288167\n",
      "Iteration 5, loss = 0.35373641\n",
      "Iteration 6, loss = 0.33320722\n",
      "Iteration 7, loss = 0.31802407\n",
      "Iteration 8, loss = 0.30430523\n",
      "Iteration 9, loss = 0.29491551\n",
      "Iteration 10, loss = 0.28607511\n",
      "Iteration 11, loss = 0.27970873\n",
      "Iteration 1, loss = 0.63993043\n",
      "Iteration 2, loss = 0.51100001\n",
      "Iteration 3, loss = 0.42531564\n",
      "Iteration 4, loss = 0.37422207\n",
      "Iteration 5, loss = 0.34735790\n",
      "Iteration 6, loss = 0.32675071\n",
      "Iteration 7, loss = 0.31031795\n",
      "Iteration 8, loss = 0.29786976\n",
      "Iteration 9, loss = 0.28796403\n",
      "Iteration 10, loss = 0.28245949\n",
      "Iteration 11, loss = 0.27442757\n",
      "Iteration 1, loss = 0.65322913\n",
      "Iteration 2, loss = 0.53576855\n",
      "Iteration 3, loss = 0.44850956\n",
      "Iteration 4, loss = 0.39150445\n",
      "Iteration 5, loss = 0.35869209\n",
      "Iteration 6, loss = 0.33754614\n",
      "Iteration 7, loss = 0.31996876\n",
      "Iteration 8, loss = 0.30801722\n",
      "Iteration 9, loss = 0.29700145\n",
      "Iteration 10, loss = 0.28743973\n",
      "Iteration 11, loss = 0.28197380\n",
      "Iteration 1, loss = 0.62626359\n",
      "Iteration 2, loss = 0.50689754\n",
      "Iteration 3, loss = 0.42363182\n",
      "Iteration 4, loss = 0.37671651\n",
      "Iteration 5, loss = 0.34802462\n",
      "Iteration 6, loss = 0.33287810\n",
      "Iteration 7, loss = 0.31880886\n",
      "Iteration 8, loss = 0.30171205\n",
      "Iteration 9, loss = 0.29260002\n",
      "Iteration 10, loss = 0.28411353\n",
      "Iteration 11, loss = 0.27626471\n",
      "Iteration 1, loss = 0.60696171\n",
      "Iteration 2, loss = 0.48700826\n",
      "Iteration 3, loss = 0.40985884\n",
      "Iteration 4, loss = 0.36536789\n",
      "Iteration 5, loss = 0.34268831\n",
      "Iteration 6, loss = 0.32206893\n",
      "Iteration 7, loss = 0.30829517\n",
      "Iteration 8, loss = 0.29584214\n",
      "Iteration 9, loss = 0.28594306\n",
      "Iteration 10, loss = 0.27733112\n",
      "Iteration 11, loss = 0.27191044\n",
      "Iteration 1, loss = 0.63325729\n",
      "Iteration 2, loss = 0.52399720\n",
      "Iteration 3, loss = 0.44193385\n",
      "Iteration 4, loss = 0.38956513\n",
      "Iteration 5, loss = 0.35772365\n",
      "Iteration 6, loss = 0.33509405\n",
      "Iteration 7, loss = 0.31766736\n",
      "Iteration 8, loss = 0.30525651\n",
      "Iteration 9, loss = 0.29752495\n",
      "Iteration 10, loss = 0.28589596\n",
      "Iteration 11, loss = 0.27974486\n",
      "Iteration 1, loss = 0.63355448\n",
      "Iteration 2, loss = 0.52194270\n",
      "Iteration 3, loss = 0.44137882\n",
      "Iteration 4, loss = 0.38831449\n",
      "Iteration 5, loss = 0.36138012\n",
      "Iteration 6, loss = 0.33792031\n",
      "Iteration 7, loss = 0.32141120\n",
      "Iteration 8, loss = 0.31221131\n",
      "Iteration 9, loss = 0.29995244\n",
      "Iteration 10, loss = 0.29004238\n",
      "Iteration 11, loss = 0.28547217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.66440524\n",
      "Iteration 2, loss = 0.55570646\n",
      "Iteration 3, loss = 0.46961350\n",
      "Iteration 4, loss = 0.41138487\n",
      "Iteration 5, loss = 0.37717879\n",
      "Iteration 6, loss = 0.35226548\n",
      "Iteration 7, loss = 0.33484702\n",
      "Iteration 8, loss = 0.32228446\n",
      "Iteration 9, loss = 0.31522031\n",
      "Iteration 10, loss = 0.30187492\n",
      "Iteration 11, loss = 0.29411281\n",
      "Iteration 1, loss = 0.61152106\n",
      "Iteration 2, loss = 0.50186564\n",
      "Iteration 3, loss = 0.42003485\n",
      "Iteration 4, loss = 0.37239793\n",
      "Iteration 5, loss = 0.34483729\n",
      "Iteration 6, loss = 0.32429187\n",
      "Iteration 7, loss = 0.31068264\n",
      "Iteration 8, loss = 0.29710431\n",
      "Iteration 9, loss = 0.28835815\n",
      "Iteration 10, loss = 0.28080063\n",
      "Iteration 11, loss = 0.27436636\n",
      "Iteration 1, loss = 0.63998370\n",
      "Iteration 2, loss = 0.52533543\n",
      "Iteration 3, loss = 0.43824370\n",
      "Iteration 4, loss = 0.38686692\n",
      "Iteration 5, loss = 0.35614834\n",
      "Iteration 6, loss = 0.33916336\n",
      "Iteration 7, loss = 0.32514375\n",
      "Iteration 8, loss = 0.31036388\n",
      "Iteration 9, loss = 0.29757565\n",
      "Iteration 10, loss = 0.29321425\n",
      "Iteration 11, loss = 0.28570825\n",
      "Iteration 1, loss = 0.64074141\n",
      "Iteration 2, loss = 0.53674602\n",
      "Iteration 3, loss = 0.44902170\n",
      "Iteration 4, loss = 0.39640341\n",
      "Iteration 5, loss = 0.36480830\n",
      "Iteration 6, loss = 0.34496114\n",
      "Iteration 7, loss = 0.32673562\n",
      "Iteration 8, loss = 0.31673722\n",
      "Iteration 9, loss = 0.30462435\n",
      "Iteration 10, loss = 0.29573114\n",
      "Iteration 11, loss = 0.28629867\n",
      "Iteration 1, loss = 0.66089435\n",
      "Iteration 2, loss = 0.54571326\n",
      "Iteration 3, loss = 0.46146543\n",
      "Iteration 4, loss = 0.40079647\n",
      "Iteration 5, loss = 0.36954659\n",
      "Iteration 6, loss = 0.34373343\n",
      "Iteration 7, loss = 0.32555059\n",
      "Iteration 8, loss = 0.31133578\n",
      "Iteration 9, loss = 0.29964269\n",
      "Iteration 10, loss = 0.29027216\n",
      "Iteration 11, loss = 0.28889279\n",
      "Iteration 1, loss = 0.64300765\n",
      "Iteration 2, loss = 0.53246248\n",
      "Iteration 3, loss = 0.44657472\n",
      "Iteration 4, loss = 0.39430967\n",
      "Iteration 5, loss = 0.36323304\n",
      "Iteration 6, loss = 0.34565086\n",
      "Iteration 7, loss = 0.32831120\n",
      "Iteration 8, loss = 0.31355853\n",
      "Iteration 9, loss = 0.30285887\n",
      "Iteration 10, loss = 0.29516694\n",
      "Iteration 11, loss = 0.28540434\n"
     ]
    }
   ],
   "source": [
    "results_data = []\n",
    "classifier_results_data = []\n",
    "for i in range(0, 15):\n",
    "    result, cls_results = hold_out_mix_ML()\n",
    "    results_data.append(result)\n",
    "    classifier_results_data.append(cls_results)\n",
    "    \n",
    "\n",
    "fireResultsDF = pd.concat(results_data)\n",
    "classifiersResultsDF = pd.concat(classifier_results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fireResultsDF.to_csv(\"Results/des_mix_pool_7_cls_results_extend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_names = [\"FIRE-KNORA-U\", \"KNORA-U\", \"FIRE-KNORA-E\", \"KNORA-E\", \"FIRE-METADES\", \"METADES\",\n",
    "                  \"FIRE-DESKNN\", \"DESKNN\", \"FIRE-MCB\", \"MCB\", \"FIRE-DESP\", \"DESP\", \"FIRE-KNOP\", \"KNOP\"]\n",
    "\n",
    "accuracy = [] \n",
    "accuracy_std =  [] \n",
    "precision = [] \n",
    "precision_std = [] \n",
    "recall = [] \n",
    "recall_std = [] \n",
    "f1_score = [] \n",
    "f1_std = []\n",
    "auc_score = []\n",
    "auc_std = []\n",
    "\n",
    "\n",
    "for n in ensemble_names:\n",
    "    accuracy.append(round(fireResultsDF[fireResultsDF.name == n].accuracy.mean(), 3))\n",
    "    accuracy_std.append(round(fireResultsDF[fireResultsDF.name == n].accuracy.std(), 3))\n",
    "    precision.append(round(fireResultsDF[fireResultsDF.name == n].precision.mean(), 3))\n",
    "    precision_std.append(round(fireResultsDF[fireResultsDF.name == n].precision.std(), 3))\n",
    "    recall.append(round(fireResultsDF[fireResultsDF.name == n].recall.mean(), 3))\n",
    "    recall_std.append(round(fireResultsDF[fireResultsDF.name == n].recall.std(), 3))\n",
    "    f1_score.append(round(fireResultsDF[fireResultsDF.name == n].f1.mean(), 3))\n",
    "    f1_std.append(round(fireResultsDF[fireResultsDF.name == n].f1.std(), 3))\n",
    "    auc_score.append(round(fireResultsDF[fireResultsDF.name == n].auc.mean(), 3))\n",
    "    auc_std.append(round(fireResultsDF[fireResultsDF.name == n].auc.std(), 3))\n",
    "    \n",
    "final_results = {\"method\": ensemble_names, \n",
    "                     \"accuracy\": accuracy, \n",
    "                     \"accuracy_std\": accuracy_std,\n",
    "                     \"precision\": precision, \n",
    "                     \"precision_std\": precision_std,\n",
    "                     \"recall\": recall, \n",
    "                     \"recall_std\": recall_std,\n",
    "                     \"f1_score\": f1_score, \n",
    "                     \"f1_std\": f1_std, \n",
    "                     \"auc\": auc_score, \n",
    "                     \"auc_std\": auc_std}\n",
    "\n",
    "finalResultsDF = pd.DataFrame.from_dict(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIRE-KNORA-U</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNORA-U</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIRE-KNORA-E</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNORA-E</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIRE-METADES</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METADES</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FIRE-DESKNN</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DESKNN</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FIRE-MCB</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MCB</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FIRE-DESP</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DESP</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FIRE-KNOP</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNOP</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          method  accuracy  accuracy_std  precision  precision_std  recall  \\\n",
       "0   FIRE-KNORA-U     0.973         0.001      0.949          0.002   1.000   \n",
       "1        KNORA-U     0.972         0.002      0.948          0.003   1.000   \n",
       "2   FIRE-KNORA-E     0.942         0.001      0.969          0.002   0.914   \n",
       "3        KNORA-E     0.944         0.001      0.973          0.002   0.914   \n",
       "4   FIRE-METADES     0.959         0.025      0.968          0.002   0.950   \n",
       "5        METADES     0.950         0.020      0.972          0.002   0.927   \n",
       "6    FIRE-DESKNN     0.971         0.015      0.956          0.002   0.988   \n",
       "7         DESKNN     0.973         0.015      0.959          0.002   0.988   \n",
       "8       FIRE-MCB     0.957         0.013      0.962          0.003   0.951   \n",
       "9            MCB     0.956         0.014      0.960          0.004   0.950   \n",
       "10     FIRE-DESP     0.974         0.001      0.951          0.002   1.000   \n",
       "11          DESP     0.974         0.002      0.950          0.003   1.000   \n",
       "12     FIRE-KNOP     0.938         0.001      0.960          0.002   0.914   \n",
       "13          KNOP     0.927         0.017      0.972          0.002   0.879   \n",
       "\n",
       "    recall_std  f1_score  f1_std    auc  auc_std  \n",
       "0        0.000     0.974   0.001  0.992    0.000  \n",
       "1        0.000     0.973   0.001  0.992    0.000  \n",
       "2        0.000     0.941   0.001  0.909    0.000  \n",
       "3        0.000     0.943   0.001  0.909    0.000  \n",
       "4        0.051     0.958   0.026  0.979    0.005  \n",
       "5        0.041     0.948   0.021  0.974    0.018  \n",
       "6        0.030     0.972   0.015  0.989    0.000  \n",
       "7        0.030     0.973   0.015  0.990    0.001  \n",
       "8        0.027     0.956   0.014  0.961    0.028  \n",
       "9        0.027     0.955   0.015  0.962    0.028  \n",
       "10       0.000     0.975   0.001  0.989    0.000  \n",
       "11       0.000     0.974   0.001  0.991    0.000  \n",
       "12       0.000     0.936   0.001  0.919    0.011  \n",
       "13       0.034     0.923   0.019  0.977    0.003  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalResultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResultsDF.to_csv(\"Results/mix_pool_results/des_mix_pool_9_cls_results_5-4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_names = [\"MLP\", \"Decision Tree\", \"Logistic Regression\", \"SVC\", \"NB\", \"Random Forest\", \"CatBoost\",\n",
    "                     \"LGBM\", \"MajorityVoting\"] \n",
    "# \"AdaBoost\", \"LGBM\"\n",
    "\n",
    "accuracy_list = []\n",
    "accuracy_std_list = []\n",
    "for n in classifiers_names:\n",
    "    accuracy_list.append(classifiersResultsDF[classifiersResultsDF.name == n].accuracy.mean())\n",
    "    accuracy_std_list.append(classifiersResultsDF[classifiersResultsDF.name == n].accuracy.std())\n",
    "\n",
    "final_cls_results = {\"classifier\": classifiers_names, \n",
    "                     \"accuracy\": accuracy_list, \n",
    "                     \"accuracy_std\": accuracy_std_list}\n",
    "\n",
    "finalClassifierResultsDF = pd.DataFrame.from_dict(final_cls_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.944948</td>\n",
       "      <td>1.191249e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.930636</td>\n",
       "      <td>2.735127e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.941748</td>\n",
       "      <td>4.596760e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.904531</td>\n",
       "      <td>4.596760e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.933981</td>\n",
       "      <td>1.447552e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.944193</td>\n",
       "      <td>1.046654e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>3.447570e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MajorityVoting</td>\n",
       "      <td>0.930636</td>\n",
       "      <td>2.735127e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classifier  accuracy  accuracy_std\n",
       "0                  MLP  0.944948  1.191249e-02\n",
       "1        Decision Tree  0.930636  2.735127e-04\n",
       "2  Logistic Regression  0.941748  4.596760e-16\n",
       "3                  SVC  0.932578  0.000000e+00\n",
       "4                   NB  0.904531  4.596760e-16\n",
       "5        Random Forest  0.933981  1.447552e-02\n",
       "6             CatBoost  0.944193  1.046654e-02\n",
       "7                 LGBM  0.932039  3.447570e-16\n",
       "8       MajorityVoting  0.930636  2.735127e-04"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalClassifierResultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.957857</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.94550</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.97275</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_std</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.960643</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.95225</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_std</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.041086</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.91725</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_std</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.957214</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.94425</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.97300</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_std</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.966643</td>\n",
       "      <td>0.031265</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.96125</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.98975</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_std</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.00950</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count      mean       std    min      25%     50%      75%  \\\n",
       "accuracy        14.0  0.957857  0.015713  0.927  0.94550  0.9580  0.97275   \n",
       "accuracy_std    14.0  0.009143  0.008646  0.001  0.00100  0.0075  0.01500   \n",
       "precision       14.0  0.960643  0.009044  0.948  0.95225  0.9600  0.96875   \n",
       "precision_std   14.0  0.002357  0.000633  0.002  0.00200  0.0020  0.00275   \n",
       "recall          14.0  0.955357  0.041086  0.879  0.91725  0.9505  0.99700   \n",
       "recall_std      14.0  0.017143  0.018773  0.000  0.00000  0.0135  0.03000   \n",
       "f1_score        14.0  0.957214  0.017039  0.923  0.94425  0.9570  0.97300   \n",
       "f1_std          14.0  0.009429  0.009246  0.001  0.00100  0.0075  0.01500   \n",
       "auc             14.0  0.966643  0.031265  0.909  0.96125  0.9780  0.98975   \n",
       "auc_std         14.0  0.006714  0.010440  0.000  0.00000  0.0005  0.00950   \n",
       "\n",
       "                 max  \n",
       "accuracy       0.974  \n",
       "accuracy_std   0.025  \n",
       "precision      0.973  \n",
       "precision_std  0.004  \n",
       "recall         1.000  \n",
       "recall_std     0.051  \n",
       "f1_score       0.975  \n",
       "f1_std         0.026  \n",
       "auc            0.992  \n",
       "auc_std        0.028  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalResultsDF.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
